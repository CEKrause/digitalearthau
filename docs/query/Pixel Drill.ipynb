{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel Drill\n",       
    "This section demonstrates the usage of a Jupyter Notebook to extract time series values of a given pixel from the specified datasets over a specified time period to a CSV file. It works for different dataset types available in DEA currently, including NBAR (Nadir BRDF (Bidirectional Reflectance Distribution Function) Adjusted Reflectance), NBART (NBAR plus Terrain illumination correction), FC (Fractional Cover) and NDVI (Normalized Difference Vegetation Index).\n",
    "\n",
    "Firstly load the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datacube\n",
    "from datetime import datetime\n",
    "from datacube.storage import masking\n",
    "import numpy as np\n",
    "import pandas\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set the pixel location, time period, product type and satellite platform you are interested. These input parameters are highlighted in yellow to show that they are controlled by the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lon = 149\n",
    "lat = -37\n",
    "acq_min = '2005-1'\n",
    "acq_max = '2015-12'\n",
    "product_type = 'ndvi'\n",
    "platform_list = ['ls5', 'ls7', 'ls8']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above product type, other options are NBAR, NBART and FC. Based on the input parameters, the output csv file name is defined as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_name = '{}_{}_{}_{}_{}_{}.csv'.format('_'.join(platform_list), product_type, \n",
    "                                             str(lon), str(lat), acq_min, acq_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which contains the platform, product type, spatial location and time range specified.\n",
    "Before performing the pixel drill function in this example, there is a support function for retrieving pixel quality data, which needs to be run in the notebook. \n",
    "This function is temporary here and will be in Data Cube API in the future, which means it will disappear in this notebook sometime in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_bit = 8\n",
    "def pq_fuser(dest, src): \n",
    "    valid_val = (1 << valid_bit) \n",
    "\n",
    "    no_data_dest_mask = ~(dest & valid_val).astype(bool) \n",
    "    np.copyto(dest, src, where=no_data_dest_mask) \n",
    "    both_data_mask = (valid_val & dest & src).astype(bool) \n",
    "    np.copyto(dest, src & dest, where=both_data_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to retrieve data for a pixel from a specified product with a specific location and time range. The output of this function is the cloud free and valid data (i.e. without nodata) value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pix_cloud_free_valid(product_type, platform, lon, lat, acq_min, acq_max):\n",
    "    # get the product name and pq product name\n",
    "    product_name = '{}_{}_albers'.format(platform, product_type)\n",
    "    pq_name = '{}_pq_albers'.format(platform)\n",
    "    #print product_name\n",
    "    \n",
    "    # use a small buffer to load data, as single pixel data is not allowed to load at this moment\n",
    "    if product_type  in ['nbar', 'nbart']:\n",
    "        # select measurements for NBAR/NBART, so that LS8 data can merge with others\n",
    "        measurements_list = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']\n",
    "        buff = dc.load(product=product_name, \n",
    "                   measurements=measurements_list,\n",
    "                   x=(lon, lon+0.00025), y=(lat, lat+0.00025), \n",
    "                   time=(acq_min, acq_max), \n",
    "                   group_by='solar_day')\n",
    "    else:        \n",
    "        buff = dc.load(product=product_name, \n",
    "                   x=(lon, lon+0.00025), y=(lat, lat+0.00025), \n",
    "                   time=(acq_min, acq_max), \n",
    "                   group_by='solar_day')\n",
    "    if buff:\n",
    "        # select the pixel of interest\n",
    "        pix = buff.isel(x=0, y=0)\n",
    "        # get cloud free data for the pixel of interest\n",
    "        pq = dc.load(product=pq_name, x=(lon, lon+0.00025), y=(lat, lat+0.00025), time=(acq_min, acq_max), \n",
    "                 group_by='solar_day', fuse_func=pq_fuser)\n",
    "        pq = pq.isel(x=0, y=0)\n",
    "        cloud_free = masking.make_mask(pq, cloud_acca='no_cloud', cloud_fmask='no_cloud', contiguous=True).pixelquality\n",
    "        pix_cld_free = pix.where(cloud_free).dropna(dim='time')\n",
    "        # remove nodata for the pixel of interest\n",
    "        pix_cld_free_valid = masking.mask_valid_data(pix_cld_free)\n",
    "        \n",
    "        pix_cld_free_valid['platform'] = (('time'), [platform]*pix_cld_free_valid.time.size)\n",
    "    \n",
    "        return pix_cld_free_valid\n",
    "    else:\n",
    "        return\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the break-down explanation of the above function:\n",
    "\n",
    "1. We need to define which product in the DEA will be used for pixel drill according to the user inputs (see the orange rectangle part labelled with 1). \n",
    "\n",
    "2. If the product type is NBAR or NBART, because Landsat 8 has different bands compared to Landsat 7 or Landsat 5, we need to explicitly define the common bands (blue, red, green, Near Infrared (nir), Short-wave Infrared 1 (swir1) and Short-wave Infrared 2 (swir2)) between the Landsat platforms. In doing this, the pixel information for each of the common bands for all Landsat platforms can be merged to form the final product (see the orange rectangle part labelled with 2).  \n",
    "\n",
    "3. At this moment, it is not possible to load data for a single pixel, we need to use a small buffer (e.g. adding another pixel in this example) to load data, and then select the data of the pixel of interest from the buffer (see the three orange rectangle parts labelled with 3).\n",
    "\n",
    "4. The last part of this function is to apply pixel quality mask to the retrieved raw data, so that only the data with cloud free and valid values is returned (see the orange rectangle part labelled with 4).\n",
    "\n",
    "Now we initialise a Datacube object that connects to DEA, giving an application name as px_drill.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='px_drill')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go through each platform (LS5, LS7 or LS8) of interest to retrieve the cloud free and valid pixel data. The output is put into a list for merging later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [    ],
   "source": [
    "pixel_data_list = []\n",
    "for platform in platform_list:\n",
    "    pixel_data = get_pix_cloud_free_valid(product_type, platform, lon, lat, acq_min, acq_max)        \n",
    "    if pixel_data:\n",
    "        pixel_data_list.append(pixel_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we merge the products into a final one incorporating all platforms of interest. The final product is sorted against time. For the purpose of demonstration, the code also plots the first band information over the time period for the final product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixel_merge = xr.concat(pixel_data_list, dim='time')\n",
    "time_sorted = pixel_merge.time.argsort()\n",
    "pixel_merge_sorted = pixel_merge.isel(time=time_sorted)\n",
    "pixel_merge_sorted.data_vars.itervalues().next().plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The final product is organised into a pandas dataframe, which can be displayed on the screen and exported to a csv file as well. This is the code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pixel_merge_sorted.to_dataframe()\n",
    "df = df.drop(['x', 'y'], axis=1)\n",
    "cols = list(df)\n",
    "cols.insert(0, cols.pop(cols.index('platform')))\n",
    "df = df[cols]\n",
    "df.to_csv(output_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output csv files name contains all relevant input parameters such as the satellite platform, product type, pixel location and the range of acquisition date. In this example, the csv file name is ls5_ls7_ls8_ndvi_149_-37_2005-1_2015_12.csv.\n",
    "\n",
    "If you would like to perform a pixel drill for other product types such as FC, NBAR or NBART, only thing to do is replacing ndvi in product_type = 'ndvi' with fc, nbar or nbart, all other corresponding information including band information and output file will automatically apply to the specific product type.  \n",
    "To view these csv files, you can use FileZilla software to transfer the files from NCI to your local working directory. To connect to VDI within FileZilla, in the host box, input sftp://hostname.nci.org.au, and 22 in the Port box while the hostname can be found in the very top of a terminal window in VDI or by typing a command (hostname) in a terminal window to find out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}